{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```Import Libraries```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "# the same function we've used before\n",
    "from helper_functions import resize_video"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```Configuration Variable```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face recognizer options ->  eigenfaces  |  fisherfaces  |  lbph (recommended for video)\n",
    "recognizer = \"lbph\"\n",
    "training_data = \"lbph_classifier.yml\"  # the path to the .yml file\n",
    "threshold = 10e5   # leave 10e5 if you don't want to specify a threshold. Otherwise, specify the value for threshold\n",
    "                   # 10e5 = 1000000  (a large number so it will always return a prediction)\n",
    "\n",
    "max_width = 800           # leave None if you don't want to resize and want to keep the original size of the video stream frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```Load Recognizer Function and Model```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the recognizer depending on the chosen option\n",
    "def load_recognizer(option, training_data):\n",
    "    if option == \"eigenfaces\":\n",
    "        face_classifier = cv2.face.EigenFaceRecognizer_create()\n",
    "    elif option == \"fisherfaces\":\n",
    "        face_classifier = cv2.face.FisherFaceRecognizer_create()\n",
    "    elif option == \"lbph\":\n",
    "        face_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
    "    else:\n",
    "        print(\"The algorithms available are: Eigenfaces, Fisherfaces and LBPH\")\n",
    "        sys.exit()\n",
    "\n",
    "    face_classifier.read(training_data) #.yml\n",
    "    return face_classifier\n",
    "\n",
    "face_classifier = load_recognizer(recognizer, training_data)\n",
    "\n",
    "# load names from pickle file\n",
    "face_names = {}\n",
    "with open(\"face_names.pickle\", \"rb\") as f:\n",
    "    original_labels = pickle.load(f)\n",
    "    # we invert key and values because it's easier if we access by ID (which is the index)\n",
    "    face_names = {v: k for k, v in original_labels.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```Return the detected face using SSD```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Return the detected face using SSD\n",
    "def recognize_faces(network, face_classifier, orig_frame, face_names, threshold, conf_min=0.7):\n",
    "    frame = orig_frame.copy()  # to keep the original frame intact (just if we want to save the full image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 117.0, 123.0))\n",
    "    network.setInput(blob)\n",
    "    detections = network.forward()\n",
    "\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_min:\n",
    "            bbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (start_x, start_y, end_x, end_y) = bbox.astype(\"int\")\n",
    "\n",
    "            # sometimes if the face is closer to the edge of the capture area the detector can return negative values, and this will crash the execution.\n",
    "            # the recommendation is to keep the face on center of the video, but just to guarantee, let's create this condition to prevent the program from crashing\n",
    "            if (start_x<0 or start_y<0 or end_x > w or end_y > h):\n",
    "                #print(start_y,end_y,start_x,end_x)\n",
    "                continue\n",
    "\n",
    "            face_roi = gray[start_y:end_y,start_x:end_x]\n",
    "            face_roi = cv2.resize(face_roi, (90, 120)) ## preferably the same size choosen when training the images (if you're using eigenfaces and fisherfaces it's mandatory that they have the sams size)\n",
    "\n",
    "            prediction, conf = face_classifier.predict(face_roi)\n",
    "\n",
    "            cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), (0, 255, 0), 2)\n",
    "\n",
    "            pred_name = face_names[prediction] if conf <= threshold else \"Not identified\"\n",
    "\n",
    "            text = \"{} -> {:.4f}\".format(pred_name, conf)\n",
    "            cv2.putText(frame, text, (start_x, start_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            # face = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "    return frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```Function Call```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\", \"res10_300x300_ssd_iter_140000.caffemodel\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```Video capture object```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video capture object\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# loop over every frame of the video stream\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # resize only if a max_width is specified\n",
    "    if max_width is not None:\n",
    "        video_width, video_height = resize_video(frame.shape[1], frame.shape[0], max_width)\n",
    "        frame = cv2.resize(frame, (video_width, video_height))\n",
    "\n",
    "    processed_frame = recognize_faces(network, face_classifier, frame, face_names, threshold)\n",
    "\n",
    "    cv2.imshow(\"Recognizing faces\", processed_frame)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "print (\"Finished!\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
